{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382a6538-436a-4848-82a3-51653fe05b62",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a03295-d195-49f5-9525-1bde3c373d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f24bec8-0f26-4f33-bd22-2cadc797884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from allover\n",
    "               the world have come and invaded us, captured our lands, conquered our minds.\n",
    "               From Alexander onwards. The Greeks, the Portuguese, the British, the French,\n",
    "               the Dutch, all of them came and looted us, took over what was ours.\n",
    "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
    "               We have not grabbed their land, their culture, their history tried to enforce our way of life on them.\n",
    "               Why? Because we respect the freedom of others.That is why my first vision is that of FREEDOM.\n",
    "               I believe that India got its first vision of this in 1857, when we started the war of independence.\n",
    "               It is this freedom that we must protect and nurture and built on.\n",
    "               If we are not free, no one will respect us. My second vision for India is DEVELOPMENT.\n",
    "               For fifty years we have been a developing nation. \n",
    "               It is time we see ourselves as a developed nation. \n",
    "               We are among top 5 nations of the world in terms of GDP. We have 10 percent growth rate in most areas.\n",
    "               Our poverty levels are falling, our achievements are being globally recognized today. \n",
    "               Yet we lack the self-confidence to see ourselves as a developed nation, \n",
    "               self reliant and self assured. Isn't this right? I have a third vision. \n",
    "               The India must stand up to the world. Because I believe that unless India stands up to the world, \n",
    "               no one will respect us. Only strength respects strength. \n",
    "               We must be strong not only as a military power but also as an economic power. \n",
    "               Both must go hand-in-hand. My good fortune was to have work with three great minds. \n",
    "               Dr Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him, \n",
    "               and Dr.Brahm Prakash, father of nuclear material. \n",
    "               I was lucky to have worked with all three of them closely and consider this \n",
    "               the great opportunity of my life.I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e85be09b-a1a3-4f5d-ab98-f39a4dedef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing sentences\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b1cfc1-356d-4940-869c-cb569f96e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff8e4fa-c4ba-4bc3-911e-62814abd068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing words\n",
    "words = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2ad09b-1980-4349-9916-aaca220e3f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dc347-e306-4fd0-b7b4-d53b66c86ab6",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4911e9c6-3391-410a-8292-9ae985dda5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9c69b-6234-4ba8-8de4-738c26cd1f32",
   "metadata": {},
   "source": [
    "`stopwords` helps to remove the words that actually have not much value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0e714f-85ac-4cdf-8732-b787d7863ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263068cb-65dd-4ea7-a5e3-6613958f4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa1bec-17c7-4488-82c9-56b970a5697a",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca38eb5c-5591-46ee-8f09-77eef0a2b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3fb7c8a-7bb0-4e80-ae8b-a4d8a9aba3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0196ae6-1222-443f-bd6e-b6982c0d3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "415df1c3-1db4-4742-97e9-84917186ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three vision India .',\n",
       " 'In 3000 year history , people allover world come invaded u , captured land , conquered mind .',\n",
       " 'From Alexander onwards .',\n",
       " 'The Greeks , Portuguese , British , French , Dutch , came looted u , took .',\n",
       " 'Yet done nation .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348e19d-d808-4813-a352-7a60589013d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
